import redis
import numpy as np
import torch
from vllm import LLM, SamplingParams
from sentence_transformers import SentenceTransformer
from redis.commands.search.field import VectorField, TagField, TextField
from redis.commands.search.indexDefinition import IndexDefinition, IndexType
from redis.commands.search.query import Query

# Redis Configuration
REDIS_HOST = "localhost"
REDIS_PORT = 6379
REDIS_INDEX_NAME = "rag_index"
VECTOR_DIM = 768  # Adjust based on embedding model
VECTOR_FIELD_NAME = "vector"

# Load Embedding Model
embedder = SentenceTransformer("all-MiniLM-L6-v2")

# Initialize Redis Client
redis_client = redis.Redis(host=REDIS_HOST, port=REDIS_PORT, decode_responses=False)

def create_redis_index():
    """Create Redis vector index if not exists."""
    try:
        redis_client.ft(REDIS_INDEX_NAME).info()
    except:
        schema = (
            TextField("text"),
            VectorField(VECTOR_FIELD_NAME, "FLAT", {
                "TYPE": "FLOAT32",
                "DIM": VECTOR_DIM,
                "DISTANCE_METRIC": "COSINE"
            })
        )
        redis_client.ft(REDIS_INDEX_NAME).create_index(schema, definition=IndexDefinition(prefix=["doc:"], index_type=IndexType.HASH))


def insert_document(doc_id, text):
    """Insert a document into Redis with vector embedding."""
    embedding = embedder.encode(text).astype(np.float32).tobytes()
    redis_client.hset(f"doc:{doc_id}", mapping={"text": text, VECTOR_FIELD_NAME: embedding})


def search_similar_docs(query, top_k=5):
    """Retrieve top-k similar documents from Redis."""
    query_vector = embedder.encode(query).astype(np.float32).tobytes()
    q = Query("*").sort_by(VECTOR_FIELD_NAME, asc=False).paging(0, top_k).return_fields("text")
    q.dialects = 2
    results = redis_client.ft(REDIS_INDEX_NAME).search(q)
    return [doc["text"] for doc in results.docs]


# Load vLLM with CodeLlama-7B-HF
llm = LLM("codellama/CodeLlama-7b-hf")

def generate_response(prompt):
    """Generate response using vLLM."""
    sampling_params = SamplingParams(temperature=0.7, top_p=0.9, max_tokens=200)
    output = llm.generate(prompt, sampling_params)[0].text
    return output


def main():
    create_redis_index()
    
    # Example document insertion
    insert_document("1", "Redis is a powerful in-memory database.")
    insert_document("2", "vLLM is optimized for serving large language models.")
    
    query = "Tell me about Redis."
    relevant_docs = search_similar_docs(query)
    
    context = "\n".join(relevant_docs)
    prompt = f"Context: {context}\nUser: {query}\nAI:"  
    response = generate_response(prompt)
    print(response)


if __name__ == "__main__":
    main()
